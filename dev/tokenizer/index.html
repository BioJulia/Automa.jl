<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Tokenizers · Automa.jl</title><meta name="title" content="Tokenizers · Automa.jl"/><meta property="og:title" content="Tokenizers · Automa.jl"/><meta property="twitter:title" content="Tokenizers · Automa.jl"/><meta name="description" content="Documentation for Automa.jl."/><meta property="og:description" content="Documentation for Automa.jl."/><meta property="twitter:description" content="Documentation for Automa.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">Automa.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../theory/">Theory</a></li><li><a class="tocitem" href="../regex/">Regex</a></li><li><a class="tocitem" href="../validators/">Validators</a></li><li class="is-active"><a class="tocitem" href>Tokenizers</a><ul class="internal"><li><a class="tocitem" href="#Making-and-using-a-tokenizer"><span>Making and using a tokenizer</span></a></li><li><a class="tocitem" href="#Using-enums-as-tokens"><span>Using enums as tokens</span></a></li><li><a class="tocitem" href="#Token-disambiguation"><span>Token disambiguation</span></a></li><li><a class="tocitem" href="#Reference"><span>Reference</span></a></li></ul></li><li><a class="tocitem" href="../parser/">Parsing buffers</a></li><li><a class="tocitem" href="../custom/">Customizing codegen</a></li><li><a class="tocitem" href="../io/">Parsing IOs</a></li><li><a class="tocitem" href="../reader/">Creating readers</a></li><li><a class="tocitem" href="../debugging/">Debugging Automa</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Tokenizers</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Tokenizers</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/BioJulia/Automa.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/BioJulia/Automa.jl/blob/master/docs/src/tokenizer.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Tokenizers-(lexers)"><a class="docs-heading-anchor" href="#Tokenizers-(lexers)">Tokenizers (lexers)</a><a id="Tokenizers-(lexers)-1"></a><a class="docs-heading-anchor-permalink" href="#Tokenizers-(lexers)" title="Permalink"></a></h1><p>A <em>tokenizer</em> or a <em>lexer</em> is a program that breaks down an input text into smaller chunks, and classifies them as one of several <em>tokens</em>. For example, consider an imagininary format that only consists of nested tuples of strings containing letters, like this:</p><pre><code class="nohighlight hljs">((&quot;ABC&quot;, &quot;v&quot;),((&quot;x&quot;, (&quot;pj&quot;,((&quot;a&quot;, &quot;k&quot;)), (&quot;L&quot;)))))</code></pre><p>Any text of this format can be broken down into a sequence of the following tokens:</p><ul><li>Left parenthesis: <code>re&quot;\(&quot;</code></li><li>Right parenthesis: <code>re&quot;\)&quot;</code></li><li>Comma: <code>re&quot;,&quot;</code></li><li>Quote: <code>re&quot;\&quot;&quot;</code></li><li>Spaces: <code>re&quot; +&quot;</code></li><li>Letters: <code>re&quot;[A-Za-z]+&quot;</code></li></ul><p>Such that e.g. <code>(&quot;XY&quot;, &quot;A&quot;)</code> can be represented as the token sequence <code>lparens, quote, XY, quote, comma, space, quote A quote rparens</code>.</p><p>Breaking the text down to its tokens is called tokenization or lexing. Note that lexing in itself is not sufficient to parse the format: Lexing is <em>context unaware</em> and doesn&#39;t understand syntax, so e.g. the text <code>&quot;((A</code> can be perfectly well tokenized to <code>quote lparens lparens A</code>, even if it&#39;s invalid syntax.</p><p>The purpose of tokenization is to make subsequent parsing easier, because each part of the text has been classified. That makes it easier to, for example, search for letters in the input. Instead of having to muck around with regex to find the letters, you use regex once to classify all text.</p><h2 id="Making-and-using-a-tokenizer"><a class="docs-heading-anchor" href="#Making-and-using-a-tokenizer">Making and using a tokenizer</a><a id="Making-and-using-a-tokenizer-1"></a><a class="docs-heading-anchor-permalink" href="#Making-and-using-a-tokenizer" title="Permalink"></a></h2><p>Let&#39;s use the example above to create a tokenizer. The most basic tokenizer defaults to using <code>UInt32</code> as tokens: You pass in a list of regex matching each token, then evaluate the resulting code:</p><pre><code class="language-julia-repl hljs">julia&gt; make_tokenizer(
           [re&quot;\(&quot;, re&quot;\)&quot;, re&quot;,&quot;, re&quot;\&quot;&quot;, re&quot; +&quot;, re&quot;[a-zA-Z]+&quot;]
       ) |&gt; eval</code></pre><p>The <code>make_tokenizer</code> function creates Julia code (an <code>Expr</code> object) that, when evaluated, defines <code>Base.iterate</code> for the <code>Tokenizer</code> type. The code above defined <code>Base.iterate(::Tokenizer{UInt32, D, 1}) where D</code> - we&#39;ll get back to the different type parameters of <code>Tokenizer</code> later.</p><p><code>Tokenizer</code>s are most easily created with the <code>tokenize</code> function. To create a <code>Tokenizer{UInt32}</code>, we can do call <code>tokenize(UInt32, data)</code>:</p><pre><code class="language-julia-repl hljs">julia&gt; iterator = tokenize(UInt32, &quot;&quot;&quot;(&quot;XY&quot;, &quot;A&quot;)&quot;&quot;&quot;); typeof(iterator)
Tokenizer{UInt32, String, 1}</code></pre><p>Meaning: A <code>Tokenizer</code> emitting <code>UInt32</code> over <code>String</code> data, of version <code>1</code>. Since we used <code>make_tokenizer</code> above to define iteration for this kind of tokenizer (one with <code>UInt32</code> tokens), we can iterate this tokenizer.</p><p>When we iterate, we get <code>Tuple{Int64, Int32, UInt32}</code> elements, with each element being:</p><ul><li>The start index of the token</li><li>The length of the token</li><li>The token itself, in this example <code>UInt32(1)</code> for &#39;(&#39;, <code>UInt32(2)</code> for &#39;)&#39; etc: </li></ul><pre><code class="language-julia-repl hljs">julia&gt; collect(iterator)
10-element Vector{Tuple{Int64, Int32, UInt32}}:
 (1, 1, 0x00000001)
 (2, 1, 0x00000004)
 (3, 2, 0x00000006)
 (5, 1, 0x00000004)
 (6, 1, 0x00000003)
 (7, 1, 0x00000005)
 (8, 1, 0x00000004)
 (9, 1, 0x00000006)
 (10, 1, 0x00000004)
 (11, 1, 0x00000002)</code></pre><p>The type of the last element in each tuple comes from the <code>Tokenizer</code> type parameter: We specified <code>UInt32</code>, so we get <code>UInt32</code> tokens.</p><p>Any data which could not be tokenized is given the error token <code>UInt32(0)</code>:</p><pre><code class="language-julia-repl hljs">julia&gt; collect(tokenize(UInt32, &quot;XY!!)&quot;))
3-element Vector{Tuple{Int64, Int32, UInt32}}:
 (1, 2, 0x00000006)
 (3, 2, 0x00000000)
 (5, 1, 0x00000002)</code></pre><p>Both <code>tokenize</code> and <code>make_tokenizer</code> take an optional argument <code>version</code>, which is <code>1</code> by default. This sets the last parameter of the <code>Tokenizer</code> struct - for example, <code>make_tokenizer(tokens::Vector{RE}; version=5)</code> defines <code>Base.iterate</code> for <code>Tokenizer{UInt32, D, 5}</code>.</p><p>By letting the user freely choose the value of the last type parameter, this allows you to create multiple different tokenizers with the same element type.</p><h2 id="Using-enums-as-tokens"><a class="docs-heading-anchor" href="#Using-enums-as-tokens">Using enums as tokens</a><a id="Using-enums-as-tokens-1"></a><a class="docs-heading-anchor-permalink" href="#Using-enums-as-tokens" title="Permalink"></a></h2><p>Using <code>UInt32</code> as tokens is not very convenient - so it&#39;s possible to use enums to create the tokenizer:</p><pre><code class="language-julia-repl hljs">julia&gt; @enum Token error lparens rparens comma quot space letters

julia&gt; make_tokenizer((error, [
           lparens =&gt; re&quot;\(&quot;,
           rparens =&gt; re&quot;\)&quot;,
           comma =&gt; re&quot;,&quot;,
           quot =&gt; re&quot;\&quot;&quot;,
           space =&gt; re&quot; +&quot;,
           letters =&gt; re&quot;[a-zA-Z]+&quot;
        ])) |&gt; eval

julia&gt; collect(tokenize(Token, &quot;XY!!)&quot;))
3-element Vector{Tuple{Int64, Int32, Token}}:
 (1, 2, letters)
 (3, 2, error)
 (5, 1, rparens)</code></pre><p>To make it even easier, you can define the enum and the tokenizer in one go:</p><pre><code class="language-julia hljs">tokens = [
    :lparens =&gt; re&quot;\(&quot;,
    :rparens =&gt; re&quot;\)&quot;,
    :comma =&gt; re&quot;,&quot;,
    :quot =&gt; re&quot;\&quot;&quot;,
    :space =&gt; re&quot; +&quot;,
    :letters =&gt; re&quot;[a-zA-Z]+&quot;
]
@eval @enum Token error $(first.(tokens)...)
make_tokenizer((error, 
    [Token(i) =&gt; j for (i,j) in enumerate(last.(tokens))]
)) |&gt; eval</code></pre><h2 id="Token-disambiguation"><a class="docs-heading-anchor" href="#Token-disambiguation">Token disambiguation</a><a id="Token-disambiguation-1"></a><a class="docs-heading-anchor-permalink" href="#Token-disambiguation" title="Permalink"></a></h2><p>It&#39;s possible to create a tokenizer where the different token regexes overlap:</p><pre><code class="language-julia-repl hljs">julia&gt; make_tokenizer([re&quot;[ab]+&quot;, re&quot;ab*&quot;, re&quot;ab&quot;]) |&gt; eval</code></pre><p>In this case, an input like <code>ab</code> will match all three regex. Which tokens are emitted is determined by two rules:</p><p>First, the emitted tokens will be as long as possible. So, the input <code>aa</code> could be emitted as one token of the regex <code>re&quot;[ab]+&quot;</code>, two tokens of the same regex, or of two tokens of the regex <code>re&quot;ab*&quot;</code>. In this case, it will be emitted as a single token of <code>re&quot;[ab]+&quot;</code>, since that will make the first token as long as possible (2 bytes), whereas the other options would only make it 1 byte long.</p><p>Second, tokens with a higher index in the input array beats previous tokens. So, <code>a</code> will be emitted as <code>re&quot;ab*&quot;</code>, as its index of 2 beats the previous regex <code>re&quot;[ab]+&quot;</code> with the index 1, and <code>ab</code> will match the third regex.</p><p>If you don&#39;t want emitted tokens to depend on these priority rules, you can set the optional keyword <code>unambiguous=true</code> in the <code>make_tokenizer</code> function, in which case <code>make_tokenizer</code> will error if any input text could be broken down into different tokens. However, note that this may cause most tokenizers to error when being built, as most tokenization processes are ambiguous.</p><h2 id="Reference"><a class="docs-heading-anchor" href="#Reference">Reference</a><a id="Reference-1"></a><a class="docs-heading-anchor-permalink" href="#Reference" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Automa.Tokenizer" href="#Automa.Tokenizer"><code>Automa.Tokenizer</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Tokenizer{E, D, C}</code></pre><p>Lazy iterator of tokens of type <code>E</code> over data of type <code>D</code>. Tokenizers are usually created with the <a href="#Automa.tokenize"><code>tokenize</code></a> function, and their iterator behaviour are defined by <a href="#Automa.make_tokenizer"><code>make_tokenizer</code></a>.</p><p><code>Tokenizer</code> works on any buffer-like object that defines <code>pointer</code> and <code>sizeof</code>. When iterated, it will return a <code>Tuple{Integer, Integer, E}</code>:</p><ul><li>The first value in the tuple is the 1-based starting index of the token in the buffer</li><li>The second is the length of the token in bytes</li><li>The third is the token.</li></ul><p>Un-tokenizable data will be emitted as the &quot;error token&quot; which must also be of type <code>E</code>.</p><p>The <code>Int</code> parameter <code>C</code> allows multiple tokenizers to be created with the otherwise same type parameters.</p><p>See also: <a href="#Automa.make_tokenizer"><code>make_tokenizer</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/BioJulia/Automa.jl/blob/b08d53b7940af2b81c780f50a98205a0a4e60cf6/src/tokenizer.jl#L1-L21">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Automa.tokenize" href="#Automa.tokenize"><code>Automa.tokenize</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">tokenize(::Type{E}, data, version=1) -&gt; Tokenizer</code></pre><p>Create a <code>Tokenizer{E, typeof(data), version}</code>, iterating tokens of type <code>E</code> over <code>data</code>.</p><p>See also: <a href="#Automa.Tokenizer"><code>Tokenizer</code></a>, <a href="#Automa.make_tokenizer"><code>make_tokenizer</code></a>, <a href="../validators/#Automa.compile"><code>compile</code></a></p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; tokenize(UInt32, &quot;hello&quot;)
Tokenizer{UInt32, String, 1}(&quot;hello&quot;)

julia&gt; tokenize(Int8, [1, 2, 3], 3)
Tokenizer{Int8, Vector{Int64}, 3}([1, 2, 3])</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/BioJulia/Automa.jl/blob/b08d53b7940af2b81c780f50a98205a0a4e60cf6/src/tokenizer.jl#L31-L47">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Automa.make_tokenizer" href="#Automa.make_tokenizer"><code>Automa.make_tokenizer</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">make_tokenizer(
    machine::TokenizerMachine;
    tokens::Tuple{E, AbstractVector{E}}= [ integers ],
    goto=true, version=1
) where E</code></pre><p>Create code which when evaluated, defines <code>Base.iterate(::Tokenizer{E, D, $version})</code>. <code>tokens</code> is a tuple of:</p><ul><li>the error token, which will be emitted for data that cannot be tokenized, and</li><li>a vector of non-error tokens of length <code>machine.n_tokens</code>.</li></ul><p>Most users should instead use the more convenient method <code>make_tokenizer(tokens)</code>.</p><p><strong>Example usage</strong></p><pre><code class="language-julia-repl hljs">julia&gt; machine = compile([re&quot;a&quot;, re&quot;b&quot;]);

julia&gt; make_tokenizer(machine; tokens=(0x00, [0x01, 0x02])) |&gt; eval

julia&gt; iter = tokenize(UInt8, &quot;abxxxba&quot;); typeof(iter)
Tokenizer{UInt8, String, 1}

julia&gt; collect(iter)
5-element Vector{Tuple{Int64, Int32, UInt8}}:
 (1, 1, 0x01)
 (2, 1, 0x02)
 (3, 3, 0x00)
 (6, 1, 0x02)
 (7, 1, 0x01)</code></pre><p>Any actions inside the input regexes will be ignored.</p><p>If <code>goto</code> (default), use the faster, but more complex goto code generator.<br/>The <code>version</code> number will set the last parameter of the <code>Tokenizer</code>, which allows you to create different tokenizers for the same element type.</p><p>See also: <a href="#Automa.Tokenizer"><code>Tokenizer</code></a>, <a href="#Automa.tokenize"><code>tokenize</code></a>, <a href="../validators/#Automa.compile"><code>compile</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/BioJulia/Automa.jl/blob/b08d53b7940af2b81c780f50a98205a0a4e60cf6/src/tokenizer.jl#L70-L110">source</a></section><section><div><pre><code class="language-julia hljs">make_tokenizer(
    tokens::Union{
        AbstractVector{RE},
        Tuple{E, AbstractVector{Pair{E, RE}}}
    };
    goto::Bool=true,
    version::Int=1,
    unambiguous=false
) where E</code></pre><p>Convenience function for both compiling a <code>TokenizerMachine</code>, then running <code>make_tokenizer</code> on it. In other words, this function returns code that when run, defines <code>iterate</code> for <code>Tokenizer{$E, D, $version} where D</code>.</p><p>If tokens are a tuple, the first element is the error token, and the next is a vector of <code>token =&gt; regex</code> pairs. If <code>tokens</code> is an <code>AbstractVector{RE}</code> <code>v</code>, the tokens defaults to <code>UInt32</code>, and it behaves as if it was <code>(UInt32(0), [UInt32(i)=&gt;r for (i,r) in pairs(v)])</code>, i.e. <code>UInt32(0)</code> is the error token.</p><p><strong>Example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; make_tokenizer([re&quot;abc&quot;, re&quot;def&quot;]) |&gt; eval

julia&gt; collect(tokenize(UInt32, &quot;abcxyzdef123&quot;))
4-element Vector{Tuple{Int64, Int32, UInt32}}:
 (1, 3, 0x00000001)
 (4, 3, 0x00000000)
 (7, 3, 0x00000002)
 (10, 3, 0x00000000)

julia&gt; make_tokenizer((0, collect(pairs([re&quot;x&quot;, re&quot;y&quot;]))); version=5) |&gt; eval

julia&gt; iter = tokenize(Int, &quot;xyaby&quot;, 5)
Tokenizer{Int64, String, 5}(&quot;xyaby&quot;)

julia&gt; collect(iter)
4-element Vector{Tuple{Int64, Int32, Int64}}:
 (1, 1, 1)
 (2, 1, 2)
 (3, 2, 0)
 (5, 1, 2)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/BioJulia/Automa.jl/blob/b08d53b7940af2b81c780f50a98205a0a4e60cf6/src/tokenizer.jl#L195-L238">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../validators/">« Validators</a><a class="docs-footer-nextpage" href="../parser/">Parsing buffers »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.7.0 on <span class="colophon-date" title="Friday 18 October 2024 15:37">Friday 18 October 2024</span>. Using Julia version 1.11.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
